Zhu H. Big data and artificial intelligence modeling for drug discovery 

Аннотация, выполненная при помощи Wordtune.

Современное открытие лекарств перешло в эпоху больших данных благодаря наличию массивных наборов данных. Подходы к искусственному интеллекту, такие как глубокое обучение, предоставляют новые решения для оценки эффективности и безопасности лекарств-кандидатов на основе моделирования и анализа больших данных.

ВВЕДЕНИЕ

Исследование и разработка лекарственных средств — сложная, дорогостоящая и трудоемкая процедура. Подходы in vitro и in silico могут снизить количество отказов от лекарств за счет определения подходящей терапевтической активности и исключения неподходящих соединений с нежелательными побочными эффектами.
Искусственный интеллект (ИИ) можно использовать для прогнозирования биологической активности и токсичности новых соединений. Однако существующие модели сложных биологических свойств далеки от оптимальных из-за использования небольших обучающих наборов, ошибок экспериментальных данных и отсутствия экспериментальных подтверждений.
Комбинаторная химия стала основным источником новых процедур химической разработки, а высокопроизводительный скрининг становится все более популярным в фармацевтической промышленности и регулирующих органах. HTS производит огромное количество биологических данных, особенно в отношении реакции лекарств на конкретные мишени.
Большие данные создают много проблем для разработки лекарств, особенно при работе с большими наборами данных из многих соединений, протестированных на многих мишенях. Для работы с большими источниками данных необходимы новые вычислительные подходы.
Недавняя разработка новых подходов к искусственному интеллекту, основанных на глубоком обучении, широко применяется в подходах к поиску лекарств в нынешнюю эпоху больших данных. Эти подходы показали большие перспективы в рациональном поиске лекарств в эпоху больших данных.

БОЛЬШИЕ ДАННЫЕ В ОТКРЫТИИ ЛЕКАРСТВ

Большие данные — это совокупность наборов данных, которые слишком велики и сложны для обработки с помощью традиционных инструментов анализа данных. Это ставит перед исследовательским сообществом новые задачи и возможности.
Параллельно с разработкой методов HTS в различных центрах скрининга было инициировано несколько проектов по обмену данными, включая PubChem и ChEMBL. Текущая статистика показывает, что PubChem содержит 97,3 миллиона соединений и 1,1 миллиона биоанализов, а ChEMBL содержит данные об активности 15 миллионов пар соединение-мишень.
Несколько источников данных специально разработаны для лекарств и кандидатов в лекарства, например, DrugBank, DrugMatrix и BindingDB. Эти базы данных содержат крупномасштабные данные об экспрессии генов в тканях крыс, которым вводили более 600 препаратов, в основном нацеленных на несколько основных органов.
Общедоступные источники больших данных, такие как база данных биоанализа PubChem, содержат большие электронные файлы, которые требуют использования новых аппаратных технологий, таких как облачные вычисления и блоки обработки графики.

ПРОБЛЕМЫ МОДЕЛИРОВАНИЯ БОЛЬШИХ ДАННЫХ: ОТСУТСТВУЮЩИЕ ДАННЫЕ И СМЕСТНЫЕ ДАННЫЕ

Профили ответа 2118 одобренных препаратов, протестированных в сравнении с 531 тестом PubChem, показаны на рисунке 2. Большинство результатов тестирования были отрицательными, и наиболее активные ответы были показаны для химиотерапевтических препаратов, которые обычно имеют серьезные побочные эффекты и другие нецелевые взаимодействия.
Отсутствующие данные — распространенная проблема моделирования больших данных. Чтобы иметь дело с отсутствующими данными, необходимы передовые статистические методы, такие как множественное вменение, и в процедурах моделирования следует уделять внимание активным, а не неактивным результатам.

ГЛУБОКОЕ ОБУЧЕНИЕ

Концепция ИИ родилась в 1950-х годах и использовалась при разработке лекарств после того, как в 1960-х годах было представлено первое исследование QSAR. Продвижению ИИ в поиске лекарств сначала способствовала разработка новых химических дескрипторов. В 1990-х и 2000-х годах в исследованиях по моделированию часто использовались подходы машинного обучения, такие как k-ближайших соседей, машины опорных векторов и случайный лес. Особое внимание уделялось проверке модели, и область применимости стала стандартной практикой разработки модели.
ИИ и вычислительная мощность улучшены для облегчения моделирования небольших обучающих наборов и применения новых методов моделирования для открытия лекарств. О первом применении нейронной сети для открытия лекарств было сообщено в 1989 году. С тех пор для открытия лекарств применялись различные подходы нейронных сетей, в том числе искусственная нейронная сеть (ИНС), которая фокусируется на процедуре выбора переменных.
В 1980-х годах нейронные сети были представлены вместе с ИНС, но не показали существенных преимуществ перед другими подходами к машинному обучению. В 2010-х разработка аппаратного обеспечения достигла вехи с появлением графических процессоров и облачных вычислений. Глубокие нейронные сети, иногда называемые глубокими нейронными сетями, были разработаны для решения сложных вопросов в области ИИ, таких как распознавание речи. Их сразу же применили в науках о жизни, где они показали значительно лучшую производительность, чем другие подходы машинного обучения для разработки лекарств.
За последние три года было проведено несколько исследований с использованием глубокого обучения для открытия лекарств, включая модели, которые предсказывают взаимодействие между лекарствами и их биологическими мишенями, и модели, которые определяют переменные из связанных задач. Однако не существует универсальных критериев для выбора соответствующих параметров моделирования и/или построения рабочего процесса моделирования.

Рациональный дизайн наноматериалов

Современные нанотехнологии сильно влияют на разработку лекарств, предлагая биосовместимые наноматериалы с желаемой терапевтической активностью и низким уровнем побочных эффектов. Ранние попытки использования ИИ в наномоделировании для открытия лекарств были основаны на молекулярно-динамическом (МД) моделировании, но эти модели требуют больших вычислительных ресурсов и не могут обеспечить быстрые прогнозы для больших баз данных. Другой вычислительный подход заключается в применении традиционных методов моделирования QSAR к наноматериалам, таким как наночастицы с одинаковыми или разными металлическими ядрами.
Текущие применения подходов ИИ в наномоделировании ограничены разработкой новых наноматериалов из-за отсутствия подходящих химических дескрипторов. Однако в некоторые исследования были включены дескрипторы, полученные на основе экспериментальных свойств или даже биологических данных. На рис. 4 представлена ​​новейшая методология моделирования наноструктур в процедуре моделирования. Эту методологию можно рассматривать как универсальный вычислитель нанологарифмов, и она использовалась для разработки и синтеза нескольких новых наночастиц с желаемой нанобиоактивностью.

Сверточные нейронные сети и моделирование изображений

CNN — это специальные подходы к сетевому моделированию, вдохновленные нейронаукой для имитации изображений в зрительной коре. Они построены таким образом, что скрытые слои особенно хорошо подходят для экранирования многомерных входных данных, таких как значения насыщенности красного, зеленого и синего, полученные из тысяч пикселей для изображения.
CNN являются одним из самых популярных подходов к глубокому обучению и используются для моделирования изображений при таких клинических диагнозах, как рак, болезнь Альцгеймера и болезни сердца. Они также использовались для открытия лекарств для анализа данных изображений, полученных в результате экспериментального тестирования наркотиков.

Персонализированная медицина

Лекарство взаимодействует с множеством мишеней, включая как на-, так и вне мишеней, а возмущение индивидуальной биологической системы молекулой лекарства определяется различными генетическими, эпигенетическими факторами и факторами окружающей среды. Персонализированная медицина опирается на научное понимание того, как уникальные характеристики отдельного пациента делают его уязвимым для болезней. Многие инициативы по созданию и обмену данными, а также усилия по компьютерному моделированию возникли для поддержки расширения точной медицины, включая программу Genomic Data Commons Национального института рака.

ВЫВОДЫ

ИИ — многообещающий метод сокращения затрат и времени на разработку лекарств. Модели глубокого обучения продемонстрировали преимущества по сравнению с традиционными подходами машинного обучения, но для применимости моделей глубокого обучения по-прежнему необходимы стандартные критерии и рабочие процессы моделирования.

Собственная анннотация. 

Исследование и разработка лекарств – это сложная, дорогостоящая, трудоемкая, процедура, предрасполагающая внедрение возможностей искусственного интеллекта еще на ранних этапах разработки лекарственных препаратов для сокращения неудач при разработке лекарственных средств. 

Как пример можно рассмотреть вычислительную модель, основанную на подходах количественной взаимосвязи структуры и активности (QSAR). К плюсам данной модели можно отнести: 
- быстрота прогнозирования новых соединений;
- возможность предсказывать простые физико-химические свойства;
- возможность достаточно точно предсказывать фармакологические свойства новых соединений с простыми механизмами.

К минусам следует отнести:
- использование небольших обучающих наборов;
- ошибки экспериментальных данных в обучающих наборах;
- отсутствие экспериментальной проверки.  

В статье широко освещена история развития применения искусственного интеллекта в области поиска лекарств. Так же прослеживается отчетливая взаимосвязь между сферой разработки искусственного интеллекта (влияния роста вычислительных мощностей, создании новых моделей анализа, совершенствования аппаратуры) с одной стороны и сферой разработки лекарств (ростом сбора данных, областями применения, сокращением срока и стоимости исследований) с другой стороны. 

В статье достаточно широко освещаются области вычислительного моделирования с использованием искусственного интеллекта для открытия лекарств: 

1.	Рациональное проектирование наноматериалов
Рациональное проектирование наноматериалов выражено в применении ИИ (искусственного интеллекта) в наномоделировании для поиска лекарств на основе молекулярно-динамическом моделировании (ML-моделирование). Позднее стали применять традиционные методы моделирования QSAR к наноматериалам.

2.	Конволюционные нейронные сети и моделирование изображений 
Особый подход к моделированию сетей – СNN, один из самых популярных подходов глубокого обучения, используется для моделирования изображений в клинических диагностиках (рак, болезнь Альцгеймера, болезни сердца). 

3.	Персонализированная медицина
Программа Genomic Data Commons Национального института рака может послужить хорошим примером использования искусственного интеллекта так как данная программа направлена на создание создание репозитория данных, позволяющего обмениваться данными в рамках геномных исследований рака в поддержку точной медицины.  

ВЫВОД.

Аннотация статьи написанная, выполненная при помощи Wordtune имеет более обобщенный вид. Следует отметить, что при помощи Wordtune, в аннотацию так же перенесена структура описываемой статьи – что является плюсом. В то же время в аннотации наблюдаются выдергивание фраз и предложений из оригинальной статьи, что в свою очередь приведет к снижению «уникальности» аннотации при проверке на Антиплагиат. 
Аннотация статьи, написанная собственноручно имеет скорее тезисный формат и отражает только на и более важные материалы, отраженные в статье («важность» субъективна). Из минусов так же следует отметить не структурированность. 

Опираясь на выше написанное могу предположить, что оба подход к написанию аннотации к статье могут имеют «право на жизнь». Однако, могу порекомендовать «симбиоз» данных способов написания аннотации. 

Zhu H. Big data and artificial intelligence modeling for drug discovery / H. Zhu. – Text : electronic // Annual Review of Pharmacology and Toxicology. – 2020. – Vol. 60. – URL: https://www.elibrary.ru/item.asp?id=43596191 (date accessed: 18.06.2023).
